[ELASTIC]
#use localhost if the ELK container is local and you are runing the python program directly
#host = localhost
#use this when you are running the replayer from a container
host = host.docker.internal

port = 9200
scheme = http
use_ssl = False
timeout = 5000
index = logstash-2020.08.03-000001
doc_type = type
size = 10000
# this sets the max number of records to size.  this should be enough for 15 minute experiments
trial_replay_query = {"size":500000,"query":{"bool":{"must":[{"match":{"msg.trial_id":"<trial_id>"}}],"must_not":[{"exists":{"field":"msg.replay_id"}}]}},"sort":[{"@timestamp":{"order":"asc"}}]}
replay_replay_query = {"size":50000,"query":{"term":{"msg.replay_id.keyword":{"value":"<trial_id>"}}},"sort":[{"@timestamp":{"order":"asc"}}]}
get_trial_id_query = {"size": 500000,"query": {"match": {"header.message_type": "trial"}}}
get_trial_id_query1 = {"size": 5000,
"query": 
    {"bool": 
	    {"must": [{"match": {"header.message_type": "trial"}},
        {"match":{"topic": "start"}}]
     }
	 },
	"_source": ["@timestamp","msg.trial_id","topic","msg.replay_id"],
	"sort":[{"@timestamp":{"order":"asc","unmapped_type":"long"}}]}
# if you include the output_file parameter, the data will also be written to file specified
[REPLAYER]
#trial_id = 05d206fa-7f4a-4adf-ad6a-263dd83ae3cf
#the output functionality has been removed.  To get a file of the trial data use the export tool.
#if the output_parameter is set, then all of the published data will also be written to the file specified.
#output_file = trial_replay.json
#the replay_agent_msgs determines if the agent topic messages are re-published (True) or filtered (False)
dont_replay_topics = ["observations/events/player/location"]
[MQTT]
#host = host.docker.internal
host = localhost
port = 1883